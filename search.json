[{"path":"http://naokiegami.com/dsl/articles/aggregate.html","id":"over","dir":"Articles","previous_headings":"","what":"Overview","title":"What if the Unit of Analysis is not the same as the Unit of Labeling?","text":"applications, unit analysis unit labeling. Researchers often annotate document, unit analysis might aggregates documents. example, users might code whether online post political candidates mentions economic policy: unit labeling online post level. researchers might interested proportion posts mentioning economic policy varies different candidates: unit analysis candidate level. , candidate multiple posts, main text-based variable defined proportion online posts mentioning economic policy candidate. applications, can users apply DSL? general, DSL applied unit analysis (.e., candidate-level data). , can prepare candidate-level data post-level data expert-coded? need two simple steps: (1) aggregating expert-coding (2) aggregating sampling probabilities","code":""},{"path":"http://naokiegami.com/dsl/articles/aggregate.html","id":"aggregating-expert-coding","dir":"Articles","previous_headings":"Overview","what":"1. Aggregating Expert-Coding","title":"What if the Unit of Analysis is not the same as the Unit of Labeling?","text":"First, discuss aggregate expert coding post-level data candidate-level data. start post level data. data, variable economy represents expert-coded labels whether given post mentions economic policy. first candidate two posts labeled, candidate, can compute proportion online posts mentioning economic policy 0. second candidates, none posts labeled, second candidate labeled. third candidate, two posts labeled. long posts randomly selected expert annotations, researchers can use mean labeled posts estimate proportion online posts mentioning economic policy 0.5 particular candidate. Variable pred_economy represents text labels predicted user-specified automated text annotation method. Variable post_sample_prob post-level sampling probability labeling. example, posts equal probability sampled 30%. general, posts randomly selected expert annotations, users can compute expert-coded mean_economy variable candidate-level ignoring NAs computing proportion online posts mentioning economic policy just focusing labeled documents. candidates labeled posts, candidates recorded non-labeled candidate-level data. variable pred_economy, users can directly compute mean within candidate. Users can implement step simply using group_by() summarize() functions tidyverse using tapply(). candidate-level, variable mean_economy expert-coded proportion posts mentioning economic policy, variable mean_pred_economy predicted proportion posts mentioning economic policy. , using mean aggregate posts within candidate, users can use function choice define text-based variable. general, long posts randomly selected expert annotations, users simply need apply definition text-based variables labeled documents (ignoring non-labeled documents) treat candidates labeled posts non-labeled.","code":"library(dsl) data(\"data_post\") # example data  head(data_post, n = 7) ##   cand_id post_id economy pred_economy post_sample_prob ## 1       1     1_1       0            0              0.3 ## 2       1     1_2       0            1              0.3 ## 6       2     2_1      NA            0              0.3 ## 7       2     2_2      NA            1              0.3 ## 3       3     3_1       1            1              0.3 ## 4       3     3_2       0            0              0.3 ## 5       3     3_3      NA            0              0.3 library(tidyverse) economy_cand <- data_post %>%    group_by(cand_id) %>%   summarize(mean_economy = mean(economy, na.rm = T),             mean_pred_economy = mean(pred_economy, na.rm = T))  # Turn NaN to NA (get ready for `dsl`) economy_cand$mean_economy[is.nan(economy_cand$mean_economy)] <- NA   head(economy_cand) ## # A tibble: 6 × 3 ##   cand_id mean_economy mean_pred_economy ##     <dbl>        <dbl>             <dbl> ## 1       1          0               0.5   ## 2       2         NA               0.5   ## 3       3          0.5             0.333 ## 4       4          0               0.5   ## 5       5          0               0.25  ## 6       6         NA               0.667"},{"path":"http://naokiegami.com/dsl/articles/aggregate.html","id":"aggregating-sampling-probabilities","dir":"Articles","previous_headings":"Overview","what":"2. Aggregating Sampling Probabilities","title":"What if the Unit of Analysis is not the same as the Unit of Labeling?","text":"Users also need translate sampling probability post-level candidate-level. particular, sampling probability expert-coding candidate probability expert-coding least one document within candidate. users randomly sample documents, need take account different numbers posts within candidate. given candidate posts, likely least one expert-coded document. compute properly, users can rely following simple function. Mathematically computes probability least one expert annotation candidate. users already know main statistical analyses candidate level, can consider two-stage sampling, .e., randomly sample candidates first randomly sample posts within candidate. Using two-stage sampling make calculation sampling probabilities candidate level even simpler. just use first stage (probability sampling candidate expert annotations).","code":"cand_sample_prob <- data_post %>%    group_by(cand_id) %>%   summarize(cand_sample_prob = 1 - prod(1 - post_sample_prob))  head(cand_sample_prob) ## # A tibble: 6 × 2 ##   cand_id cand_sample_prob ##     <dbl>            <dbl> ## 1       1            0.51  ## 2       2            0.51  ## 3       3            0.657 ## 4       4            0.760 ## 5       5            0.760 ## 6       6            0.657"},{"path":"http://naokiegami.com/dsl/articles/aggregate.html","id":"merging-other-candidate-level-data","dir":"Articles","previous_headings":"Overview","what":"3. Merging Other Candidate-level data","title":"What if the Unit of Analysis is not the same as the Unit of Labeling?","text":"prepare final candidate-level data, can combine two data sets well candidate-level data. , users might merge candidate-level data.","code":"# First we merge (mean_economy, mean_pred_economy) and cand_sample_prob cand_main <- merge(economy_cand, cand_sample_prob, by = \"cand_id\") data(\"data_cand\") # example candidate-level data  data_cand_merged <- merge(cand_main, data_cand, by = \"cand_id\") head(data_cand_merged) ##   cand_id mean_economy mean_pred_economy cand_sample_prob gender edu ideology ## 1       1          0.0         0.5000000           0.5100      0   2        5 ## 2       2           NA         0.5000000           0.5100      0   4        3 ## 3       3          0.5         0.3333333           0.6570      1   4        2 ## 4       4          0.0         0.5000000           0.7599      1   4        3 ## 5       5          0.0         0.2500000           0.7599      0   5        4 ## 6       6           NA         0.6666667           0.6570      1   4        3"},{"path":"http://naokiegami.com/dsl/articles/aggregate.html","id":"fitting-dsl-with-the-candidate-level-data","dir":"Articles","previous_headings":"Overview","what":"4. Fitting DSL with the Candidate-level Data","title":"What if the Unit of Analysis is not the same as the Unit of Labeling?","text":"Finally, run dsl candidate-level data specifying sampling probability.","code":"out_agg <- dsl(model = \"lm\",                 formula = mean_economy ~ gender + edu + ideology,                predicted_var =  \"mean_economy\",                prediction = \"mean_pred_economy\",                sample_prob = \"cand_sample_prob\",                data = data_cand_merged) ## Cross-Fitting: 1/10..2/10..3/10..4/10..5/10..6/10..7/10..8/10..9/10..10/10.. summary(out_agg) ## ================== ## DSL Specification: ## ================== ## Model:  lm ## Call:  mean_economy ~ gender + edu + ideology ##  ## Predicted Variables:  mean_economy ## Prediction:  mean_pred_economy ##  ## Number of Labeled Observations:  674 ## Random Sampling for Labeling with Equal Probability:  No ## (Sampling probabilities are defined in `sample_prob`) ##  ## ============= ## Coefficients: ## ============= ##             Estimate Std. Error CI Lower CI Upper p value     ## (Intercept)   0.4057     0.0696   0.2693   0.5421  0.0000 *** ## gender       -0.0099     0.0348  -0.0780   0.0583  0.3883     ## edu           0.0005     0.0128  -0.0246   0.0256  0.4852     ## ideology     -0.0091     0.0134  -0.0353   0.0172  0.2493     ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## 95% confidence intervals (CI) are reported."},{"path":"http://naokiegami.com/dsl/articles/faq.html","id":"power","dir":"Articles","previous_headings":"","what":"How Many Documents Should Experts Annotate?","title":"Frequently Asked Questions","text":"practice, researchers might wonder many documents expert annotate. help researchers common scenarios, develop data-driven power analysis: annotating small number documents, can predict many documents researchers need annotate order achieve user-specified size standard error. example, use data introduced Get Started page. particular, users can apply function power_dsl() predict standard errors different size expert-coded data. Researchers can use arguments dsl add one argument labeled_size, represents number expert-coded documents predict standard errors. Recall current number expert-coded documents 500. first row shows current standard errors coefficients. remaining rows show predicted standard errors. Importantly, increase number expert annotations countyWrong, standard errors countyWrong predicted decrease sharply. variables, see similarly sharp reduction variables already observed entire data. Small reduction standard errors come correlations countyWrong. Researchers can use function plot visualize power analysis.  Finally, researchers can also apply power_dsl() directly output function dsl(). can see power_out2 identical power_out.","code":"library(dsl) data(\"PanChen\") head(PanChen) ##   countyWrong pred_countyWrong SendOrNot prefecWrong connect2b prevalence ## 1           0                0         0           0         1          0 ## 2           0                1         0           0         0          0 ## 3           1                0         0           0         0          0 ## 4          NA                0         0           0         1          0 ## 5          NA                0         0           1         0          0 ## 6          NA                0         0           0         1          0 ##   regionj groupIssue ## 1       0          1 ## 2       0          1 ## 3       0          1 ## 4       0          1 ## 5       0          1 ## 6       0          1 power_out <- power_dsl(labeled_size = c(600, 700, 800, 900, 1000),                        model = \"logit\",                         formula = SendOrNot ~ countyWrong + prefecWrong +                           connect2b + prevalence + regionj + groupIssue,                        predicted_var = \"countyWrong\",                        prediction = \"pred_countyWrong\",                        data = PanChen) ## Cross-Fitting: 1/10..2/10..3/10..4/10..5/10..6/10..7/10..8/10..9/10..10/10.. ## Power Analysis: 1/10..2/10..3/10..4/10..5/10..6/10..7/10..8/10..9/10..10/10.. summary(power_out) ##  ## ========================== ## Predicted Standard Errors: ## ========================== ##      (Intercept) countyWrong prefecWrong connect2b prevalence   regionj ## 500    0.3620969   0.2230176   0.2969560 0.1197007  0.1519793 0.4565769 ## 600    0.3615976   0.2046064   0.2962925 0.1189793  0.1514914 0.4563394 ## 700    0.3612406   0.1903684   0.2958177 0.1184612  0.1511421 0.4561697 ## 800    0.3609726   0.1789480   0.2954611 0.1180712  0.1508795 0.4560424 ## 900    0.3607640   0.1695345   0.2951835 0.1177670  0.1506749 0.4559433 ## 1000   0.3605971   0.1616093   0.2949612 0.1175230  0.1505111 0.4558640 ##      groupIssue ## 500   0.3596752 ## 600   0.3596009 ## 700   0.3595479 ## 800   0.3595080 ## 900   0.3594771 ## 1000  0.3594523 ## --- plot(power_out, coef_name = \"countyWrong\") out <- dsl(model = \"logit\",             formula = SendOrNot ~ countyWrong + prefecWrong +               connect2b + prevalence + regionj + groupIssue,            predicted_var = \"countyWrong\",            prediction = \"pred_countyWrong\",            data = PanChen) ## Cross-Fitting: 1/10..2/10..3/10..4/10..5/10..6/10..7/10..8/10..9/10..10/10.. power_out2 <- power_dsl(dsl_out = out,                          labeled_size = c(600, 700, 800, 900, 1000)) ##  ## Power Analysis: 1/10..2/10..3/10..4/10..5/10..6/10..7/10..8/10..9/10..10/10.. summary(power_out2) ##  ## ========================== ## Predicted Standard Errors: ## ========================== ##      (Intercept) countyWrong prefecWrong connect2b prevalence   regionj ## 500    0.3620969   0.2230176   0.2969560 0.1197007  0.1519793 0.4565769 ## 600    0.3615976   0.2046064   0.2962925 0.1189793  0.1514914 0.4563394 ## 700    0.3612406   0.1903684   0.2958177 0.1184612  0.1511421 0.4561697 ## 800    0.3609726   0.1789480   0.2954611 0.1180712  0.1508795 0.4560424 ## 900    0.3607640   0.1695345   0.2951835 0.1177670  0.1506749 0.4559433 ## 1000   0.3605971   0.1616093   0.2949612 0.1175230  0.1505111 0.4558640 ##      groupIssue ## 500   0.3596752 ## 600   0.3596009 ## 700   0.3595479 ## 800   0.3595080 ## 900   0.3594771 ## 1000  0.3594523 ## ---"},{"path":"http://naokiegami.com/dsl/articles/faq.html","id":"variable","dir":"Articles","previous_headings":"","what":"What Types of Predicted Variables Can DSL Handle?","title":"Frequently Asked Questions","text":"shown various examples Get Started Page Models Available DSL, users can incorporate predicted variables (.e., text-based variables) outcome /independent variables. example, users text-based variables outcome independent variables, can specify vector predicted_var. one variable predicted_var, rows observe variables predicted_var counted labeled, rows least one NA variables predicted_var counted non-labeled.","code":"data(\"data_logit\") # example data   head(data_logit) ##    Y         X1 pred_Y    pred_X1         X2          X3          X4 ## 1  0 -0.1443742      0  0.9486148 -0.2079232 -0.06932595  1.65748976 ## 2  1 -1.2864079      1 -1.8766233 -1.6961906 -0.27274691  1.54678252 ## 3  1 -1.4665386      1 -2.4866911 -0.6212224 -0.70787173 -0.27913330 ## 4  0 -1.3554115      1  0.5138155  1.2299990 -0.86519213  0.18177847 ## 5 NA         NA      1 -2.1116582  0.6624512  1.19504665 -0.02724476 ## 6 NA         NA      1 -0.6391120 -0.8971608  1.20072203 -0.51241357 ##            X5          X6         X7        X8           X9        X10 ## 1  0.96825927  0.05389556 -2.0762690 0.2653279  1.458743948  0.4127003 ## 2 -0.46626141  0.73182950 -1.7677551 1.0790758 -0.003172833 -0.5313550 ## 3 -0.26973904 -1.75925076 -0.1585703 0.6823146  0.050500221 -1.2679467 ## 4  0.41947288 -0.32375937  0.3226157 0.5131867 -2.065367939  1.6111660 ## 5 -0.94927647  1.01808653  0.7608077 1.6830265 -1.907959205 -0.6979879 ## 6  0.09162689  1.15086391 -0.7917356 0.9765960 -0.144924483 -1.2848539 out_logit <- dsl(model = \"logit\",                   formula = Y ~ X1 + X2 + X4,                  predicted_var = c(\"Y\", \"X1\"),                  prediction = c(\"pred_Y\", \"pred_X1\"),                  data = data_logit) ## Cross-Fitting: 1/10..2/10..3/10..4/10..5/10..6/10..7/10..8/10..9/10..10/10.."},{"path":"http://naokiegami.com/dsl/articles/faq.html","id":"sample","dir":"Articles","previous_headings":"","what":"(More Complex) Sampling Strategies?","title":"Frequently Asked Questions","text":"Researchers might consider sampling strategies expert annotations random sampling equal probabilities. long sampling probability document decided researchers greater zero, DSL applicable. example, DSL allows stratified block sampling schemes (.e., change sampling probability documents based document-level observed covariates) can cover case sampling probability depends LLM annotation, document-level covariates, independent variables, outcome variable. generality important researchers might want -sample documents difficult annotate. function dsl(), using complex sampling strategies, users specify sampling probability document. example, following data set, set sampling probability expert annotation 30% documents X1 = 1 set 10% documents X1 = 0. see , variable sample_prob 0.3 X1 = 1 0.1 X1 = 0. Thus, random sampling unequal probabilities. running dsl(), users just need specify unequal sampling probability argument sample_prob. users rely random sampling unequal probabilities, Random Sampling Equal Probability becomes .","code":"data(\"data_unequal\") # example data  head(data_unequal) ##    Y pred_Y sample_prob X1         X2           X3 ## 1  0      1         0.1  0 -0.7075315  0.774843489 ## 2  0      0         0.1  0 -0.1282225 -0.351258120 ## 3  0      1         0.3  1 -0.9908576  0.733213596 ## 4 NA      1         0.3  1 -1.1068022 -0.403284103 ## 5 NA      1         0.1  0  0.2493619  0.510531594 ## 6 NA      1         0.1  0 -1.0298485  0.004936994 out_unequal <- dsl(model = \"logit\",                     formula = Y ~ X1 + X2 + X3,                    predicted_var = c(\"Y\"),                    prediction = c(\"pred_Y\"),                    sample_prob = \"sample_prob\",                    data = data_unequal) ## Cross-Fitting: 1/10..2/10..3/10..4/10..5/10..6/10..7/10..8/10..9/10..10/10.. summary(out_unequal) ## ================== ## DSL Specification: ## ================== ## Model:  logit ## Call:  Y ~ X1 + X2 + X3 ##  ## Predicted Variables:  Y ## Prediction:  pred_Y ##  ## Number of Labeled Observations:  334 ## Random Sampling for Labeling with Equal Probability:  No ## (Sampling probabilities are defined in `sample_prob`) ##  ## ============= ## Coefficients: ## ============= ##             Estimate Std. Error CI Lower CI Upper p value   ## (Intercept)  -0.2157     0.1185  -0.4480   0.0165  0.0343 * ## X1            0.1073     0.3349  -0.5491   0.7637  0.3744   ## X2            0.1074     0.1086  -0.1055   0.3203  0.1615   ## X3           -0.0449     0.1157  -0.2717   0.1820  0.3492   ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## 95% confidence intervals (CI) are reported."},{"path":"http://naokiegami.com/dsl/articles/faq.html","id":"cluster","dir":"Articles","previous_headings":"","what":"How Can We Implement Cluster Standard Errors in DSL?","title":"Frequently Asked Questions","text":"Users need supply variable name defines clusters argument cluster function dsl(). option available model types (lm, logit, felm). users applied cluster standard errors, level clustering reported Coefficients table, e.g., Standard errors clustered state.","code":"data(\"data_felm\") # example data   out_felm_one <- dsl(model = \"felm\",                      formula = log_pcap ~ log_gsp + log_pc + unemp,                     predicted_var =  \"log_gsp\",                     prediction = \"pred_log_gsp\",                     fixed_effect = \"oneway\",                      index = c(\"state\"),                      cluster = \"state\",                     data = data_felm) ## Cross-Fitting: 1/10..2/10..3/10..4/10..5/10..6/10..7/10..8/10..9/10..10/10.. summary(out_felm_one) ## ================== ## DSL Specification: ## ================== ## Model:  felm (oneway) ## Call:  log_pcap ~ log_gsp + log_pc + unemp ## Fixed Effects:  state ##  ## Predicted Variables:  log_gsp ## Prediction:  pred_log_gsp ##  ## Number of Labeled Observations:  334 ## Random Sampling for Labeling with Equal Probability: Yes ##  ## ============= ## Coefficients: ## ============= ##         Estimate Std. Error CI Lower CI Upper p value     ## log_gsp   0.0031     0.0020  -0.0007   0.0069  0.0558   . ## log_pc    0.5357     0.0419   0.4537   0.6178  0.0000 *** ## unemp     0.0067     0.0021   0.0025   0.0108  0.0008 *** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## 95% confidence intervals (CI) are reported. ## Standard errors are clustered by state."},{"path":"http://naokiegami.com/dsl/articles/faq.html","id":"unit","dir":"Articles","previous_headings":"","what":"What if the Unit of Analysis is not the same as the Unit of Labeling?","title":"Frequently Asked Questions","text":"applications, unit analysis unit labeling. Researchers often annotate document, unit analysis might aggregates documents. example, users might code whether online post political candidates mentions economic policy: unit labeling online post level. researchers might interested proportion posts mentioning economic policy varies different candidates: unit analysis candidate level. , candidate multiple posts, main text-based variable defined proportion online posts mentioning economic policy candidate. applications, can users apply DSL? provide step step guide .","code":""},{"path":"http://naokiegami.com/dsl/articles/faq.html","id":"category","dir":"Articles","previous_headings":"","what":"How to use DSL for Estimating the Category Proportions over Time or across Groups?","title":"Frequently Asked Questions","text":"Many scholars interested estimating proportion documents user-specified category. example, might study proportion censored documents changes time, proportion social media posts containing hate speech differs across groups, Democrats Republicans. questions can analyzed within DSL framework, . start basic data structure dsl. data, Y denotes whether document belongs category interest, pred_Y denotes predicted value. estimate category proportions time example, approach applies estimating category proportions across groups. estimate category proportions time, researchers can regress text category time using linear regression without intercept. numerically equivalent computing DSL estimates within year separately. implement , researchers can simply add -1 formula remove intercept. Note estimation approach uses numerical equivalence linear regression (lm) subgroup means (scholars use linear regression compute difference--means randomized experiments), thus, researchers need use logistic regression (logit). , coefficients front year estimated category proportions year.","code":"data(\"data_time\") head(data_time) ##    Y pred_Y year ## 1  1      1 2001 ## 2  1      0 2001 ## 3  0      1 2001 ## 4 NA      1 2001 ## 5 NA      0 2001 ## 6 NA      0 2001 out_time <- dsl(model = \"lm\",                 formula = Y ~ as.factor(year) - 1,                 predicted_var = \"Y\",                 prediction = \"pred_Y\",                 data = data_time) ## Cross-Fitting: 1/10..2/10..3/10..4/10..5/10..6/10..7/10..8/10..9/10..10/10.. summary(out_time) ## ================== ## DSL Specification: ## ================== ## Model:  lm ## Call:  Y ~ as.factor(year) - 1 ##  ## Predicted Variables:  Y ## Prediction:  pred_Y ##  ## Number of Labeled Observations:  500 ## Random Sampling for Labeling with Equal Probability: Yes ##  ## ============= ## Coefficients: ## ============= ##                     Estimate Std. Error CI Lower CI Upper p value     ## as.factor(year)2001   0.6451     0.0652   0.5173   0.7729   0e+00 *** ## as.factor(year)2002   0.6234     0.0654   0.4953   0.7515   0e+00 *** ## as.factor(year)2003   0.2956     0.0808   0.1372   0.4541   1e-04 *** ## as.factor(year)2004   0.4444     0.0693   0.3087   0.5802   0e+00 *** ## as.factor(year)2005   0.6288     0.0722   0.4873   0.7703   0e+00 *** ## as.factor(year)2006   0.4275     0.0728   0.2849   0.5702   0e+00 *** ## as.factor(year)2007   0.5710     0.0766   0.4209   0.7211   0e+00 *** ## as.factor(year)2008   0.6703     0.0674   0.5381   0.8024   0e+00 *** ## as.factor(year)2009   0.4960     0.0639   0.3707   0.6212   0e+00 *** ## as.factor(year)2010   0.4761     0.0704   0.3381   0.6142   0e+00 *** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## 95% confidence intervals (CI) are reported."},{"path":"http://naokiegami.com/dsl/articles/faq.html","id":"sl","dir":"Articles","previous_headings":"","what":"How Can We Internally Implement Supervised Machine Learning for Predictions?","title":"Frequently Asked Questions","text":"One common use cases package researchers LLM annotations prediction key text-based variables defined predicted_var. Alternatively, researchers can also internally implement classical supervised machine learning methods make predictions using expert-coded data. building SuperLearner package, offer following 41 supervised ML methods. researchers internally implement classical supervised machine learning methods, data structure looks like data used classical supervised machine learning. example, Y requires text annotation 10 variables available predict Y. internally implement supervised machine learning methods, users decide supervised machine learning model (specified sl_method) predictors (specified feature). formula, researchers can specify downstream statistical model run predicting Y. example, main downstream analysis linear regression outcome Y independent variables X1,X2, X4. , set sl_method = \"grf\" use generalized random forest supervised machine learning model. Finally, many existing methods require stringent assumptions prediction errors, often strict rules whether variables used prediction stage can overlap variables main analyses. Fortunately, DSL, researchers need worry issues DSL require assumption prediction error. researchers can include variables main statistical analyses (X1, X2, X4) prediction step well.","code":"available_method() ##  [1] \"grf\"              \"bartMachine\"      \"bayesglm\"         \"biglasso\"         ##  [5] \"caret\"            \"caret.rpart\"      \"cforest\"          \"earth\"            ##  [9] \"gam\"              \"gbm\"              \"glm\"              \"glm.interaction\"  ## [13] \"glmnet\"           \"ipredbagg\"        \"kernelKnn\"        \"knn\"              ## [17] \"ksvm\"             \"lda\"              \"leekasso\"         \"lm\"               ## [21] \"loess\"            \"logreg\"           \"mean\"             \"nnet\"             ## [25] \"nnls\"             \"polymars\"         \"qda\"              \"randomForest\"     ## [29] \"ranger\"           \"ridge\"            \"rpart\"            \"rpartPrune\"       ## [33] \"speedglm\"         \"speedlm\"          \"step\"             \"step.forward\"     ## [37] \"step.interaction\" \"stepAIC\"          \"svm\"              \"xgboost\" data(\"data_sl\")  # example data  head(data_sl) ##            Y          X1          X2         X3          X4         X5 ## 1 -0.2050247 -0.09910396 -0.87960666  0.8015421  1.29028152  0.8532547 ## 2 -1.4856037  1.23123941  1.99007602  0.3868839 -0.07223693 -1.2962462 ## 3  0.9894281  0.46408759  0.42323988 -0.1097634  0.25241778 -0.9464925 ## 4         NA -1.12227958 -0.06897893 -0.4601287  1.49975679  1.5618861 ## 5         NA -0.67877168 -0.33290315 -1.4747134 -1.89504047  0.5137869 ## 6         NA  0.04734624 -0.18367264 -1.1965101  0.11178831  0.1975828 ##           X6         X7          X8         X9        X10 ## 1 -0.4914913 -1.0640511  0.01688910  1.8391539 -2.3456977 ## 2 -1.2428339  0.0644001  1.92829279 -1.3745543 -0.5644520 ## 3  0.8812547  1.5719390 -1.31725336  0.9007558  0.4595894 ## 4  0.2493619  0.5105316  0.02339191 -0.3850724 -1.2070657 ## 5  0.2394639 -1.4016767 -0.30634290  1.5934046  0.4291247 ## 6 -1.6337523 -0.3078537 -0.51741473 -1.1128772 -0.5747400 out_lm_grf <- dsl(model = \"lm\",                    formula = Y ~ X1 + X2 + X4,                   predicted_var = c(\"Y\"),                   sl_method = \"grf\",                   feature =  c(\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X7\", \"X8\", \"X9\", \"X10\"),                   data = data_sl) ## Cross-Fitting: 1/10..2/10..3/10..4/10..5/10..6/10..7/10..8/10..9/10..10/10.. summary(out_lm_grf) ## ================== ## DSL Specification: ## ================== ## Model:  lm ## Call:  Y ~ X1 + X2 + X4 ##  ## Predicted Variables:  Y ## Prediction:  with predictors specified in `covariates` ##  ## Number of Labeled Observations:  500 ## Random Sampling for Labeling with Equal Probability: Yes ##  ## ============= ## Coefficients: ## ============= ##             Estimate Std. Error CI Lower CI Upper p value     ## (Intercept)   0.0288     0.0497  -0.0686   0.1262  0.2812     ## X1            0.3982     0.0533   0.2938   0.5026  0.0000 *** ## X2           -0.2433     0.0496  -0.3406  -0.1461  0.0000 *** ## X4           -0.2696     0.0498  -0.3672  -0.1720  0.0000 *** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## 95% confidence intervals (CI) are reported."},{"path":"http://naokiegami.com/dsl/articles/intro.html","id":"over","dir":"Articles","previous_headings":"","what":"Overview","title":"Get Started with dsl","text":"text--data applications, one common tasks text annotation (text classification) generate text-based variables subsequent statistical analyses. example, researchers might first annotate whether online post contains hate speech can later study likely post hate speech types interventions can reduce hate speech. last decade, scholars used variety supervised machine learning (ML) methods automate text annotation step training machines mimic expert-coding. recently, growing number papers propose using large language models (LLMs), ChatGPT, automate text annotations predicting expert annotations. Given researchers can adapt LLMs perform wide range text annotation tasks simply changing prompts, automated LLM annotations present exciting opportunities social sciences. text annotation essential, first step. Social scientists often primarily interested using text labels predicted automated methods key variables subsequent statistical analyses. vast majority current applications, researchers treat predicted text-based variables observed without error: ignore prediction errors first step automated text annotation. However, ignoring prediction errors first step text annotation, even errors small, leads substantial bias, invalid confidence intervals, wrong p-values downstream statistical analyses text-based variables. Biases prediction errors exist even prediction accuracy text classification step extremely high, e.g., 90% even 95%. prediction errors random—prediction errors correlated observed unobserved variables include downstream analyses. practice, means substantive statistical conclusions can easily flip researchers ignore prediction errors automated text annotation methods. Design-based supervised learning (DSL) general framework using predicted variables downstream statistical analyses without suffering bias due prediction errors. Unlike existing approaches, DSL allows researchers obtain statistically valid estimates standard errors, even automated text annotation methods arbitrary non-random prediction errors. , DSL combines large-scale (potentially biased) automated annotations smaller number high-quality expensive expert annotations using doubly robust bias-correction step. Please read Egami, Hinck, Stewart, Wei (2023) methodological details.","code":""},{"path":"http://naokiegami.com/dsl/articles/intro.html","id":"dsl","dir":"Articles","previous_headings":"","what":"dsl: DSL Estimator","title":"Get Started with dsl","text":"example, use Pan Chen (2018), studies whether online complaints accusing corruption local officials reported upper-level governments China. example, variable countyWrong (whether post accuses corruption county-level politicians) requires text annotation. randomly sampled subset data (500 documents) provide expert annotations variable. Variable countyWrong represents expert labels, takes NA given observation labeled experts. Variable pred_countyWrong represents text labels predicted user-specified automated text annotation method, e.g., annotations given user-specified LLM. example, variable pred_countyWrong represent annotations given GPT-4. Unlike variable countyWrong, variable pred_countyWrong available entire data. remaining six columns represent key variables included main statistical analyses. users include pred_countyWrong instead countyWrong downstream analyses, suffer biases due prediction errors. users worry prediction errors use subset data expert-coded countyWrong, miss large number observations. Researchers can use dsl perform main statistical analyses analyzing data taking account prediction errors. example, interested running logistic regression model regressing binary outcome SendOrNot set independent variables, including countyWrong. Researchers can obtain summary output using function summary(). first outputs specification DSL estimation, including number labeled observations sampling process expert annotations. users specify explicitly, function dsl() assumes random sampling equal probabilities. users deployed sampling strategy random sampling equal probabilities, explicitly specify using argument sample_prob fitting dsl (please see page). coefficients, researchers can interpret estimates standard errors usual regression analyses. package implements hetroskedasticity-robust standard errors default. users want compute cluster-robust standard errors, can use argument cluster, explain . package supports different types regression models: linear regression (lm), logistic regression (logit), linear fixed-effects regression (felm). learn model, please visit Models Available DSL. help users apply DSL various practical settings, answer frequently asked questions Frequently Asked Questions, including determine required number expert annotations, incorporate complex sampling strategies expert annotations, handle cluster standard errors. References: Egami, Hinck, Stewart, Wei. (2024). “Using Large Language Model Annotations Social Sciences: General Framework Using Predicted Variables Downstream Analyses.” Egami, Hinck, Stewart, Wei. (2023). Using Imperfect Surrogates Downstream Inference: Design-based Supervised Learning Social Science Applications Large Language Models, Advances Neural Information Processing Systems (NeurIPS). Pan Chen. (2018). Concealing Corruption: Chinese Officials Distort Upward Reporting Online Grievances. American Political Science Review 112, 3, 602–620.","code":"library(dsl) data(\"PanChen\") head(PanChen) ##   countyWrong pred_countyWrong SendOrNot prefecWrong connect2b prevalence ## 1           0                0         0           0         1          0 ## 2           0                1         0           0         0          0 ## 3           1                0         0           0         0          0 ## 4          NA                0         0           0         1          0 ## 5          NA                0         0           1         0          0 ## 6          NA                0         0           0         1          0 ##   regionj groupIssue ## 1       0          1 ## 2       0          1 ## 3       0          1 ## 4       0          1 ## 5       0          1 ## 6       0          1 out <- dsl(model = \"logit\",             formula = SendOrNot ~ countyWrong + prefecWrong +               connect2b + prevalence + regionj + groupIssue,            predicted_var = \"countyWrong\",            prediction = \"pred_countyWrong\",            data = PanChen) ## Cross-Fitting: 1/10..2/10..3/10..4/10..5/10..6/10..7/10..8/10..9/10..10/10.. summary(out) ## ================== ## DSL Specification: ## ================== ## Model:  logit ## Call:  SendOrNot ~ countyWrong + prefecWrong + connect2b + prevalence + regionj + groupIssue ##  ## Predicted Variables:  countyWrong ## Prediction:  pred_countyWrong ##  ## Number of Labeled Observations:  500 ## Random Sampling for Labeling with Equal Probability: Yes ##  ## ============= ## Coefficients: ## ============= ##             Estimate Std. Error CI Lower CI Upper p value     ## (Intercept)   2.0978     0.3621   1.3881   2.8075  0.0000 *** ## countyWrong  -0.2617     0.2230  -0.6988   0.1754  0.1203     ## prefecWrong  -1.1162     0.2970  -1.6982  -0.5342  0.0001 *** ## connect2b    -0.0788     0.1197  -0.3134   0.1558  0.2552     ## prevalence   -0.3271     0.1520  -0.6250  -0.0292  0.0157   * ## regionj       0.1253     0.4566  -0.7695   1.0202  0.3919     ## groupIssue   -2.3222     0.3597  -3.0271  -1.6172  0.0000 *** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## 95% confidence intervals (CI) are reported."},{"path":"http://naokiegami.com/dsl/articles/model.html","id":"lm","dir":"Articles","previous_headings":"","what":"lm: Linear Regression","title":"Models Available in DSL","text":"Researchers can implement DSL linear regression specifying model = \"lm\". example, variable Y requires text annotation (take NA given observation labeled experts). Variable pred_Y represents predictions Y.","code":"library(dsl) data(\"data_lm\") # example data  head(data_lm) ##          Y   pred_Y         X1         X2         X3        X4         X5 ## 1 3.337877 3.288469 0.84678708 0.10927346 0.15178520 0.4336862 0.07082542 ## 2 1.283851 1.353864 0.59445495 0.19281988 0.77950672 0.4498675 0.30573402 ## 3 3.618762 3.603551 0.91183977 0.97745425 0.19939829 0.3630903 0.97453388 ## 4       NA 1.402226 0.24259237 0.03956956 0.02819825 0.8497914 0.95381503 ## 5       NA 3.842970 0.51535594 0.78112420 0.31758914 0.5531493 0.46124773 ## 6       NA 0.601493 0.09942167 0.28733200 0.44238525 0.5460361 0.83561538 out_lm <- dsl(model = \"lm\",                formula = Y ~ X1 + X2 + X3 + X4 + X5,               predicted_var = \"Y\",               prediction = \"pred_Y\",               data = data_lm) ## Cross-Fitting: 1/10..2/10..3/10..4/10..5/10..6/10..7/10..8/10..9/10..10/10.. summary(out_lm) ## ================== ## DSL Specification: ## ================== ## Model:  lm ## Call:  Y ~ X1 + X2 + X3 + X4 + X5 ##  ## Predicted Variables:  Y ## Prediction:  pred_Y ##  ## Number of Labeled Observations:  245 ## Random Sampling for Labeling with Equal Probability: Yes ##  ## ============= ## Coefficients: ## ============= ##             Estimate Std. Error CI Lower CI Upper p value     ## (Intercept)   0.6450     0.0714   0.5050   0.7850  0.0000 *** ## X1            2.1293     0.0685   1.9951   2.2635  0.0000 *** ## X2            2.1033     0.0645   1.9769   2.2296  0.0000 *** ## X3            0.0448     0.0687  -0.0898   0.1794  0.2572     ## X4            0.0022     0.0635  -0.1223   0.1267  0.4861     ## X5            0.0257     0.0593  -0.0906   0.1419  0.3326     ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## 95% confidence intervals (CI) are reported."},{"path":"http://naokiegami.com/dsl/articles/model.html","id":"logit","dir":"Articles","previous_headings":"","what":"logit: Logistic Regression","title":"Models Available in DSL","text":"Researchers can implement DSL logistic regression specifying model = \"logit\". requires arguments model = \"lm\". example, variables Y X1 require text annotation (take NA given observation labeled experts). Variables pred_Y pred_X1 represent predictions Y X1. example, dsl can handle cases multiple variables require text annotations.","code":"data(\"data_logit\") # example data  head(data_logit) ##    Y         X1 pred_Y    pred_X1         X2          X3          X4 ## 1  0 -0.1443742      0  0.9486148 -0.2079232 -0.06932595  1.65748976 ## 2  1 -1.2864079      1 -1.8766233 -1.6961906 -0.27274691  1.54678252 ## 3  1 -1.4665386      1 -2.4866911 -0.6212224 -0.70787173 -0.27913330 ## 4  0 -1.3554115      1  0.5138155  1.2299990 -0.86519213  0.18177847 ## 5 NA         NA      1 -2.1116582  0.6624512  1.19504665 -0.02724476 ## 6 NA         NA      1 -0.6391120 -0.8971608  1.20072203 -0.51241357 ##            X5          X6         X7        X8           X9        X10 ## 1  0.96825927  0.05389556 -2.0762690 0.2653279  1.458743948  0.4127003 ## 2 -0.46626141  0.73182950 -1.7677551 1.0790758 -0.003172833 -0.5313550 ## 3 -0.26973904 -1.75925076 -0.1585703 0.6823146  0.050500221 -1.2679467 ## 4  0.41947288 -0.32375937  0.3226157 0.5131867 -2.065367939  1.6111660 ## 5 -0.94927647  1.01808653  0.7608077 1.6830265 -1.907959205 -0.6979879 ## 6  0.09162689  1.15086391 -0.7917356 0.9765960 -0.144924483 -1.2848539 out_logit <- dsl(model = \"logit\",                   formula = Y ~ X1 + X2 + X4,                  predicted_var = c(\"Y\", \"X1\"),                  prediction = c(\"pred_Y\", \"pred_X1\"),                  data = data_logit) ## Cross-Fitting: 1/10..2/10..3/10..4/10..5/10..6/10..7/10..8/10..9/10..10/10.. summary(out_logit) ## ================== ## DSL Specification: ## ================== ## Model:  logit ## Call:  Y ~ X1 + X2 + X4 ##  ## Predicted Variables:  Y, X1 ## Prediction:  pred_Y, pred_X1 ##  ## Number of Labeled Observations:  487 ## Random Sampling for Labeling with Equal Probability: Yes ##  ## ============= ## Coefficients: ## ============= ##             Estimate Std. Error CI Lower CI Upper p value     ## (Intercept)  -0.7386     0.1000  -0.9346  -0.5426  0.0000 *** ## X1            0.2208     0.1044   0.0162   0.4255  0.0172   * ## X2            0.0242     0.0974  -0.1667   0.2151  0.4019     ## X4            0.2742     0.1022   0.0739   0.4745  0.0037  ** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## 95% confidence intervals (CI) are reported."},{"path":"http://naokiegami.com/dsl/articles/model.html","id":"felm","dir":"Articles","previous_headings":"","what":"felm: Fixed Effects Linear Regression","title":"Models Available in DSL","text":"Researchers can implement DSL fixed effects linear regression specifying model = \"felm\". example, variable log_gsp requires text annotation (takes NA given observation labeled experts). Variable pred_log_gsp represents predictions log_gsp.","code":"data(\"data_lm\")  # example data  head(data_felm) ##     state year  log_gsp pred_log_gsp log_pcap   log_pc unemp ## 1 ALABAMA 1970       NA     9.738913 9.617981 10.48553   4.7 ## 2 ALABAMA 1971 10.28790    10.287899 9.648720 10.52675   5.2 ## 3 ALABAMA 1972 10.35147    10.351469 9.678618 10.56283   4.7 ## 4 ALABAMA 1973 10.41721    10.417209 9.705418 10.59873   3.9 ## 5 ALABAMA 1974 10.42671    10.426706 9.726910 10.64679   5.5 ## 6 ALABAMA 1975 10.42240    10.422400 9.759401 10.69130   7.7"},{"path":"http://naokiegami.com/dsl/articles/model.html","id":"one-way-fixed-effects","dir":"Articles","previous_headings":"felm: Fixed Effects Linear Regression","what":"One-way Fixed Effects","title":"Models Available in DSL","text":"implement DSL one-way fixed effects regression, users can set fixed_effect = \"oneway\". Use index denote column defines fixed effects. Users can also cluster standard errors specifying variable name argument cluster (cluster argument also avaiable models).","code":"out_felm_one <- dsl(model = \"felm\",                      formula = log_pcap ~ log_gsp + log_pc + unemp,                     predicted_var =  \"log_gsp\",                     prediction = \"pred_log_gsp\",                     fixed_effect = \"oneway\",                      index = c(\"state\"),                      cluster = \"state\",                     data = data_felm) ## Cross-Fitting: 1/10..2/10..3/10..4/10..5/10..6/10..7/10..8/10..9/10..10/10.. summary(out_felm_one) ## ================== ## DSL Specification: ## ================== ## Model:  felm (oneway) ## Call:  log_pcap ~ log_gsp + log_pc + unemp ## Fixed Effects:  state ##  ## Predicted Variables:  log_gsp ## Prediction:  pred_log_gsp ##  ## Number of Labeled Observations:  334 ## Random Sampling for Labeling with Equal Probability: Yes ##  ## ============= ## Coefficients: ## ============= ##         Estimate Std. Error CI Lower CI Upper p value     ## log_gsp   0.0031     0.0020  -0.0007   0.0069  0.0558   . ## log_pc    0.5357     0.0419   0.4537   0.6178  0.0000 *** ## unemp     0.0067     0.0021   0.0025   0.0108  0.0008 *** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## 95% confidence intervals (CI) are reported. ## Standard errors are clustered by state."},{"path":"http://naokiegami.com/dsl/articles/model.html","id":"two-way-fixed-effects","dir":"Articles","previous_headings":"felm: Fixed Effects Linear Regression","what":"Two-way Fixed Effects","title":"Models Available in DSL","text":"implement DSL two-way fixed effects regression, users can set fixed_effect = \"twoways\". Use index (vector length 2) denote columns define fixed effects.","code":"out_felm_two <- dsl(model = \"felm\",                      formula = log_pcap ~ log_gsp + log_pc + unemp,                     predicted_var =  \"log_gsp\",                     prediction = \"pred_log_gsp\",                     fixed_effect = \"twoways\",                      index = c(\"state\", \"year\"),                      cluster = \"state\",                     data = data_felm) ## Cross-Fitting: 1/10..2/10..3/10..4/10..5/10..6/10..7/10..8/10..9/10..10/10.. summary(out_felm_two) ## ================== ## DSL Specification: ## ================== ## Model:  felm (twoways) ## Call:  log_pcap ~ log_gsp + log_pc + unemp ## Fixed Effects:  state and year ##  ## Predicted Variables:  log_gsp ## Prediction:  pred_log_gsp ##  ## Number of Labeled Observations:  334 ## Random Sampling for Labeling with Equal Probability: Yes ##  ## ============= ## Coefficients: ## ============= ##         Estimate Std. Error CI Lower CI Upper p value     ## log_gsp   0.0025     0.0017  -0.0009   0.0060  0.0722   . ## log_pc    0.4275     0.0748   0.2809   0.5741  0.0000 *** ## unemp     0.0093     0.0034   0.0027   0.0159  0.0028  ** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## 95% confidence intervals (CI) are reported. ## Standard errors are clustered by state."},{"path":"http://naokiegami.com/dsl/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Naoki Egami. Maintainer, author. Musashi Hinck. Author. Brandon M. Stewart. Author. Hanying Wei. Author.","code":""},{"path":"http://naokiegami.com/dsl/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Egami N, Hinck M, M. Stewart B, Wei H (2025). dsl: Design-based Supervised Learning. R package version 0.1.0, http://naokiegami.com/dsl/.","code":"@Manual{,   title = {dsl: Design-based Supervised Learning},   author = {Naoki Egami and Musashi Hinck and Brandon {M. Stewart} and Hanying Wei},   year = {2025},   note = {R package version 0.1.0},   url = {http://naokiegami.com/dsl/}, }"},{"path":[]},{"path":"http://naokiegami.com/dsl/index.html","id":"overview","dir":"","previous_headings":"dsl: Design-based Supervised Learning","what":"Overview","title":"Design-based Supervised Learning","text":"R package dsl implements design-based supervised learning (DSL) proposed Egami, Hinck, Stewart, Wei (2024), generalizes extends first proposal DSL Egami, Hinck, Stewart, Wei (2023). DSL general estimation framework using predicted variables statistical analyses. package especially useful researchers trying use large language models (LLMs) annotate large number documents analyze subsequently. DSL allows users obtain statistically valid estimates standard errors, even LLM annotations contain arbitrary non-random prediction errors biases. learn use package, please start Get Started Page.","code":""},{"path":"http://naokiegami.com/dsl/index.html","id":"installation-instructions","dir":"","previous_headings":"dsl: Design-based Supervised Learning","what":"Installation Instructions","title":"Design-based Supervised Learning","text":"can install recent development version using devtools package. First install devtools using following code. Note : , load devtools use function install_github() install dsl:","code":"if(!require(devtools)) install.packages(\"devtools\") library(devtools) install_github(\"naoki-egami/dsl\", dependencies = TRUE)"},{"path":"http://naokiegami.com/dsl/index.html","id":"information","dir":"","previous_headings":"dsl: Design-based Supervised Learning","what":"Information","title":"Design-based Supervised Learning","text":"Authors: Naoki Egami (Maintainer) Musashi Hinck Brandon M. Stewart Hanying Wei Reference: Egami, Hinck, Stewart, Wei. (2024). “Using Large Language Model Annotations Social Sciences: General Framework Using Predicted Variables Downstream Analyses.” Egami, Hinck, Stewart, Wei. (2023). “Using Imperfect Surrogates Downstream Inference: Design-based Supervised Learning Social Science Applications Large Language Models,” Advances Neural Information Processing Systems (NeurIPS).","code":""},{"path":"http://naokiegami.com/dsl/reference/PanChen.html","id":null,"dir":"Reference","previous_headings":"","what":"Data for Pan and Chen (2018) — PanChen","title":"Data for Pan and Chen (2018) — PanChen","text":"Data Pan Chen (2018)","code":""},{"path":"http://naokiegami.com/dsl/reference/PanChen.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data for Pan and Chen (2018) — PanChen","text":"data","code":""},{"path":"http://naokiegami.com/dsl/reference/PanChen.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data for Pan and Chen (2018) — PanChen","text":"Pan, J. Chen, K. (2018). Concealing Corruption: Chinese Officials Distort Upward Reporting Online Grievances. American Political Science Review 112, 3, 602–620.","code":""},{"path":"http://naokiegami.com/dsl/reference/available_method.html","id":null,"dir":"Reference","previous_headings":"","what":"Showing available methods for Supervised Machine Learning — available_method","title":"Showing available methods for Supervised Machine Learning — available_method","text":"Showing available methods Supervised Machine Learning","code":""},{"path":"http://naokiegami.com/dsl/reference/available_method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Showing available methods for Supervised Machine Learning — available_method","text":"","code":"available_method(print_out = TRUE)"},{"path":"http://naokiegami.com/dsl/reference/available_method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Showing available methods for Supervised Machine Learning — available_method","text":"print_out Whether print output (TRUE) (FALSE).","code":""},{"path":"http://naokiegami.com/dsl/reference/available_method.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Showing available methods for Supervised Machine Learning — available_method","text":"availabel_method returns list available methods.","code":""},{"path":"http://naokiegami.com/dsl/reference/data_cand.html","id":null,"dir":"Reference","previous_headings":"","what":"Candidate-level data for illustrating applications where the unit of analysis differs from the unit of labeling. — data_cand","title":"Candidate-level data for illustrating applications where the unit of analysis differs from the unit of labeling. — data_cand","text":"Candidate-level data illustrating applications unit analysis differs unit labeling.","code":""},{"path":"http://naokiegami.com/dsl/reference/data_cand.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Candidate-level data for illustrating applications where the unit of analysis differs from the unit of labeling. — data_cand","text":"data","code":""},{"path":"http://naokiegami.com/dsl/reference/data_felm.html","id":null,"dir":"Reference","previous_headings":"","what":"Data for illustrating model = ","title":"Data for illustrating model = ","text":"Data illustrating model = \"felm\".","code":""},{"path":"http://naokiegami.com/dsl/reference/data_felm.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data for illustrating model = ","text":"data","code":""},{"path":"http://naokiegami.com/dsl/reference/data_lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Data for illustrating model = ","title":"Data for illustrating model = ","text":"Data illustrating model = \"lm\".","code":""},{"path":"http://naokiegami.com/dsl/reference/data_lm.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data for illustrating model = ","text":"data","code":""},{"path":"http://naokiegami.com/dsl/reference/data_logit.html","id":null,"dir":"Reference","previous_headings":"","what":"Data for illustrating model = ","title":"Data for illustrating model = ","text":"Data illustrating model = \"logit\".","code":""},{"path":"http://naokiegami.com/dsl/reference/data_logit.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data for illustrating model = ","text":"data","code":""},{"path":"http://naokiegami.com/dsl/reference/data_post.html","id":null,"dir":"Reference","previous_headings":"","what":"Post-level data for illustrating applications where the unit of analysis differs from the unit of labeling. — data_post","title":"Post-level data for illustrating applications where the unit of analysis differs from the unit of labeling. — data_post","text":"Post-level data illustrating applications unit analysis differs unit labeling.","code":""},{"path":"http://naokiegami.com/dsl/reference/data_post.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Post-level data for illustrating applications where the unit of analysis differs from the unit of labeling. — data_post","text":"data","code":""},{"path":"http://naokiegami.com/dsl/reference/data_sl.html","id":null,"dir":"Reference","previous_headings":"","what":"Data for illustrating supervised machine learning — data_sl","title":"Data for illustrating supervised machine learning — data_sl","text":"Data illustrating supervised machine learning","code":""},{"path":"http://naokiegami.com/dsl/reference/data_sl.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data for illustrating supervised machine learning — data_sl","text":"data","code":""},{"path":"http://naokiegami.com/dsl/reference/data_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Data for illustrating the estimation of category proportions over time — data_time","title":"Data for illustrating the estimation of category proportions over time — data_time","text":"Data illustrating estimation category proportions time","code":""},{"path":"http://naokiegami.com/dsl/reference/data_time.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data for illustrating the estimation of category proportions over time — data_time","text":"data","code":""},{"path":"http://naokiegami.com/dsl/reference/data_unequal.html","id":null,"dir":"Reference","previous_headings":"","what":"Data for illustrating applications where sampling probabilities are unequal. — data_unequal","title":"Data for illustrating applications where sampling probabilities are unequal. — data_unequal","text":"Data illustrating applications sampling probabilities unequal.","code":""},{"path":"http://naokiegami.com/dsl/reference/data_unequal.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data for illustrating applications where sampling probabilities are unequal. — data_unequal","text":"data","code":""},{"path":"http://naokiegami.com/dsl/reference/dsl.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimating Regression using the DSL framework — dsl","title":"Estimating Regression using the DSL framework — dsl","text":"Estimating Regression using DSL framework","code":""},{"path":"http://naokiegami.com/dsl/reference/dsl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimating Regression using the DSL framework — dsl","text":"","code":"dsl(   model = \"lm\",   formula,   predicted_var,   prediction = NULL,   data,   cluster = NULL,   labeled = NULL,   sample_prob = NULL,   index = NULL,   fixed_effect = \"oneway\",   sl_method = \"grf\",   feature = NULL,   family = \"gaussian\",   cross_fit = 5,   sample_split = 10,   seed = 1234 )"},{"path":"http://naokiegami.com/dsl/reference/dsl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimating Regression using the DSL framework — dsl","text":"model regression model dsl currently supports lm (linear regression), logit (logistic regression), felm (fixed-effects regression). formula formula used specified regression model. predicted_var vector column names data correspond variables need predicted. prediction vector column names data correspond predictions predicted_var. data data frame. class data.frame. cluster column name data indicates level cluster standard errors calculated. Default NULL. labeled (Optional) column name data indicates observation labeled. vector 1 (labeled) 0 (non-labeled). NULL, function assumes observations NA predicted_var non-labeled observations labeled. sample_prob (Optional) column name data correspond sampling probability labeling particular observation. NULL, function assumes random sampling equal probabilities. index (Used model = \"felm\") vector column names specifying fixed effects. fixed_effect = oneway, one element. fixed_effect = twoways, two elements, e.g., index = c(\"state\", \"year\"). fixed_effect (Used model = \"felm\") type fixed effects regression run. oneway (one-way fixed effects) twoways (two-way fixed effects). sl_method name supervised machine learning model used internally predict predicted_var fine-tuning prediction using predictors (specified feature) prediction = NULL. Users can run available_method() see available supervised machine learning methods. Default grf (generalized random forest). feature vector column names data correspond predictors used fit supervised machine learning (specified sl_method). family (Used making predictions) variable type predicted_var. Default gaussian. cross_fit fold cross-fitting. Default 5. sample_split number sampling-splitting. Default 10. seed Numeric seed used internally. Default 1234.","code":""},{"path":"http://naokiegami.com/dsl/reference/dsl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimating Regression using the DSL framework — dsl","text":"dsl returns object dsl class. coefficients: Estimated coefficients. standard_errors: Estimated standard errors. vcov: Estimated variance-covariance matrix. RMSE: Root mean squared error internal prediction step. internal: Outputs used internal use.","code":""},{"path":"http://naokiegami.com/dsl/reference/plot.power_dsl.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing estimates from DSL estimators — plot.power_dsl","title":"Summarizing estimates from DSL estimators — plot.power_dsl","text":"Summarizing estimates DSL estimators","code":""},{"path":"http://naokiegami.com/dsl/reference/plot.power_dsl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing estimates from DSL estimators — plot.power_dsl","text":"","code":"# S3 method for class 'power_dsl' plot(x, coef_name = NULL, ...)"},{"path":"http://naokiegami.com/dsl/reference/plot.power_dsl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing estimates from DSL estimators — plot.power_dsl","text":"x output function power_dsl. coef_name name coefficient users want visualize. NULL, function visualizes every coefficient. ... arguments.","code":""},{"path":"http://naokiegami.com/dsl/reference/power_dsl.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Analysis for DSL Regression — power_dsl","title":"Power Analysis for DSL Regression — power_dsl","text":"Power Analysis DSL Regression","code":""},{"path":"http://naokiegami.com/dsl/reference/power_dsl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Analysis for DSL Regression — power_dsl","text":"","code":"power_dsl(   labeled_size = NULL,   dsl_out = NULL,   model = \"lm\",   formula,   predicted_var,   prediction = NULL,   data,   cluster = NULL,   labeled = NULL,   sample_prob = NULL,   index = NULL,   fixed_effect = \"oneway\",   sl_method = \"grf\",   feature = NULL,   family = \"gaussian\",   cross_fit = 5,   sample_split = 10,   seed = 1234 )"},{"path":"http://naokiegami.com/dsl/reference/power_dsl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Analysis for DSL Regression — power_dsl","text":"labeled_size vector indicating number labeled documents function predicts standard errors. dsl_out output function dsl. supplied, remaining arguments overwritten arguments specified output dsl. NULL, function use arguments specified . model regression model dsl currently supports lm (linear regression), logit (logistic regression), felm (fixed-effects regression). formula formula used specified regression model. predicted_var vector column names data correspond variables need predicted. prediction vector column names data correspond predictions predicted_var. data data frame. class data.frame. cluster column name data indicates level cluster standard errors calculated. Default NULL. labeled (Optional) column name data indicates observation labeled. vector 1 (labeled) 0 (non-labeled). NULL, function assumes observations NA predicted_var non-labeled observations labeled. sample_prob (Optional) column name data correspond sampling probability labeling particular observation. NULL, function assumes random sampling equal probabilities. index (Used model = \"felm\") vector column names specifying fixed effects. fixed_effect = oneway, one element. fixed_effect = twoways, two elements, e.g., index = c(\"state\", \"year\"). fixed_effect (Used model = \"felm\") type fixed effects regression run. oneway (one-way fixed effects) twoways (two-way fixed effects). sl_method name supervised machine learning model used internally predict predicted_var fine-tuning prediction using predictors (specified feature) prediction = NULL. Users can run available_method() see available supervised machine learning methods. Default grf (generalized random forest). feature vector column names data correspond predictors used fit supervised machine learning (specified sl_method). family (Used making predictions) variable type predicted_var. Default gaussian. cross_fit fold cross-fitting. Default 5. sample_split number sampling-splitting. Default 10. seed Numeric seed used internally. Default 1234.","code":""},{"path":"http://naokiegami.com/dsl/reference/power_dsl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Analysis for DSL Regression — power_dsl","text":"dsl returns object dsl class. predicted_se: Predicted standard errors coefficients. first row shows current standard errors coefficients. remaining rows show predicted standard errors. labeled_size: vector indicating number labeled documents function predicts standard errors. dsl_out: output function dsl.","code":""},{"path":"http://naokiegami.com/dsl/reference/summary.dsl.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary function for dsl — summary.dsl","title":"Summary function for dsl — summary.dsl","text":"Summary function dsl","code":""},{"path":"http://naokiegami.com/dsl/reference/summary.dsl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary function for dsl — summary.dsl","text":"","code":"# S3 method for class 'dsl' summary(object, ci = 0.95, digits = 4, ...)"},{"path":"http://naokiegami.com/dsl/reference/summary.dsl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary function for dsl — summary.dsl","text":"object output function dsl. ci coverage rate confidence intervals. Default 0.95, reports 95% confidence intervals. digits number digits reported. ... arguments.","code":""},{"path":"http://naokiegami.com/dsl/reference/summary.power_dsl.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing estimates from DSL estimators — summary.power_dsl","title":"Summarizing estimates from DSL estimators — summary.power_dsl","text":"Summarizing estimates DSL estimators","code":""},{"path":"http://naokiegami.com/dsl/reference/summary.power_dsl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing estimates from DSL estimators — summary.power_dsl","text":"","code":"# S3 method for class 'power_dsl' summary(object, ...)"},{"path":"http://naokiegami.com/dsl/reference/summary.power_dsl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing estimates from DSL estimators — summary.power_dsl","text":"object output function power_dsl. ... arguments.","code":""}]
